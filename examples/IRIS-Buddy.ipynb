{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e55e65-4ba9-4cc9-aa48-97643b8a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65041f89-ba4e-487a-b601-7e18277256d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    print(Run)\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ae3bc-0a9f-4eb7-8f0d-1edec10041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = 0.9\n",
    "canons  = 2\n",
    "random_state = 1\n",
    "num_samples = 250\n",
    "dense_layer_length = 10\n",
    "table = 'iris'\n",
    "if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770b5c5c-d828-45a7-b990-918e77bc6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f64ab69-d4c7-4493-85f6-0b1a5bd9ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                   names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# 2. Separate features (X) and target (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# 3. Preprocess the data\n",
    "# Encode the target labels into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 0, 1, 2 for Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=holdout, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3d5e31-85b2-4e71-9390-2967b70084db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 135)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f048365c-7774-45e8-9918-b7c76a7d587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:36:34.337090: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 09:36:34.346974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746801394.359053   10046 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746801394.362619   10046 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 09:36:34.374575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from os import chdir\n",
    "#chdir('..')\n",
    "import sopy as sp\n",
    "from connect import conn\n",
    "engine = conn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ee3ea-7dfb-4b46-acac-763d848b1f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af490b56-5375-4320-910f-bb5f6d49c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = pd.Series()\n",
    "\n",
    "d = pd.DataFrame(X, columns = range(1,5)).describe()\n",
    "ir= pd.DataFrame(X, columns = range(1,5))\n",
    "cl= pd.Series(y_encoded)\n",
    "\n",
    "spacings   = [ d[c]['std']/4 for c in d ]\n",
    "means    = [ d[c]['mean'] for c in d]\n",
    "sigmas   =  [ [ ir.loc[cl[cl==cl1].index, c].describe()['std'] for c in d ] for cl1 in cl.unique() ]\n",
    "wavenumbers = 4*[0.]\n",
    "phis        = 4*[0.]\n",
    "lattices = [ np.arange( d[c]['min'], d[c]['max'], spacings[dd] ) for dd,c in enumerate(d) ]\n",
    "\n",
    "Run['canons'] = canons\n",
    "Run['holdout'] = holdout\n",
    "Run['random_state'] = random_state\n",
    "Run['dense_layer_length'] = dense_layer_length\n",
    "\n",
    "d = pd.DataFrame(X, columns = range(1,5)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,5))\n",
    "cl= pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c6c7f-a6d8-4007-b942-3b1c0707d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8be514-03c5-47fa-bda6-368b23824e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 09:36:38.161101: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "u = sp.vector() \n",
    "for index in cl[cl==0].index:\n",
    "    u += sp.vector().gaussian(a=1, ls = 4*[0], positions = ir.loc[index].values, sigmas = sigmas[0] , lattices = lattices, wavenumbers = wavenumbers, phis = phis) \n",
    "u = u.mul(1./u.n()).fibonacci( partition = canons )\n",
    "print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a861940a-acc2-4d5d-a35d-6c736c80e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "u2 = sp.vector() \n",
    "for index in cl[cl==1].index:\n",
    "    u2 += sp.vector().gaussian(a=1, ls = 4*[0], positions = ir.loc[index].values, sigmas = sigmas[1] , lattices = lattices, wavenumbers = wavenumbers, phis = phis) \n",
    "u2 = u2.mul(1./u2.n()).fibonacci( partition = canons )\n",
    "print(len(u2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59184cec-aa78-4b40-8b1c-d73757158f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "u3 = sp.vector() \n",
    "for index in cl[cl==2].index:\n",
    "    u3 += sp.vector().gaussian(a=1, ls = 4*[0], positions = ir.loc[index].values, sigmas = sigmas[2] , lattices = lattices, wavenumbers = wavenumbers, phis = phis) \n",
    "u3 = u3.mul(1./u3.n()).fibonacci( partition = canons )\n",
    "print(len(u3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2b848-a564-41ef-8d17-fdd129ac18b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ece78c-088c-4e75-a2a1-1238af4d096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a95b66-1e1b-485d-9adf-2d98ccf25333",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [ [np.argmax([ v.dot(sp.vector().delta(a=1./np.sqrt( np.prod(spacings)), positions = x, spacings = spacings , lattices = lattices , wavenumbers = wavenumbers, phis = phis)) for v in [u,u2,u3] ])]for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8774c6-1464-4efc-9bb1-32ef1a78a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sop = accuracy_score(y_test, y_pred)\n",
    "accuracy_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd7642a-85d8-4d06-890b-076a0a5063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "##GEMINI GENERATED THIS CODE\n",
    "\n",
    "#y_train = label_encoder.fit_transform(y_train)  # 0, 1, 2 for Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "#y_test = label_encoder.fit_transform(y_test)  # 0, 1, 2 for Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Define the Single Layer Dense Neural Network (Softmax Regression)\n",
    "class SingleLayerNN:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.01, epochs=1000):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5  # Initialize weights randomly\n",
    "        self.bias = np.zeros((1, output_size))  # Initialize bias to zeros\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.weights) + self.bias\n",
    "        self.y_hat = self.softmax(self.z)\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, X, y, y_hat):\n",
    "        m = X.shape[0]\n",
    "        dz = y_hat - self.one_hot_encode(y)\n",
    "        dw = (1/m) * np.dot(X.T, dz)\n",
    "        db = (1/m) * np.sum(dz, axis=0, keepdims=True)\n",
    "        return dw, db\n",
    "\n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(y), self.output_size))\n",
    "        one_hot[np.arange(len(y)), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def update_parameters(self, dw, db):\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.forward(X_train)\n",
    "            dw, db = self.backward(X_train, y_train, y_hat)\n",
    "            self.update_parameters(dw, db)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = self.categorical_cross_entropy(self.one_hot_encode(y_train), y_hat)\n",
    "                #print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_prob = self.forward(X_test)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def categorical_cross_entropy(self, y_true, y_pred):\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        epsilon = 1e-15\n",
    "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "        return loss\n",
    "\n",
    "# 5. Initialize and train the neural network\n",
    "input_size = X_train_scaled.shape[1]  # Number of features (4)\n",
    "output_size = len(np.unique(y_encoded))  # Number of classes (3)\n",
    "learning_rate = 0.1\n",
    "epochs = 2000\n",
    "\n",
    "model = SingleLayerNN(input_size, output_size, learning_rate, epochs)\n",
    "model.train(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate the model\n",
    "accuracy_snn = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy_snn:.4f}\")\n",
    "\n",
    "# You can also print the classification report for more detailed metrics\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a949ce-e18e-427e-bfc4-ec8767419fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [ v.sample(num_samples) for v in [u,u2,u3] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b780edc-b65b-4afa-a86a-eb674152284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run['num_samples']= num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8638221-28a8-436a-8c9c-eb7e7acc9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_buddy = np.transpose(np.array(np.concat([samples[0],samples[1],samples[2]]),dtype= np.float64),(2,0,1))[0]\n",
    "y_train_buddy = np.array(num_samples*[0] + num_samples*[1] + num_samples*[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43302b36-4493-4ac0-8fa7-3ef5dc631a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathanjerke/QuantumGalaxies/Andromeda/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1683\n",
      "Test Accuracy: 0.9481\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    }
   ],
   "source": [
    "##GEMINI GENERATED THIS CODE\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled_buddy = scaler2.fit_transform(X_train_buddy)\n",
    "X_test_scaled = scaler2.transform(X_test)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "y_train_buddy_encode = keras.utils.to_categorical(y_train_buddy)  \n",
    "y_test_encode = keras.utils.to_categorical(y_test)  \n",
    "model = keras.Sequential([\n",
    "    layers.Dense(dense_layer_length, activation='relu', input_shape=(4,)), \n",
    "    layers.Dense(3, activation='softmax')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled_buddy, y_train_buddy_encode, epochs=100, batch_size=16, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test_encode, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "#Make predictions.\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5732df54-f511-495a-bc90-ac14818f6165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "accuracy_buddy = accuracy_score(predicted_labels,y_test )\n",
    "print(f\"\\nTest Accuracy: {accuracy_buddy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e65ebf7d-5922-457c-94d3-76ea1c16c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run['accuracy_sop'] = accuracy_sop\n",
    "Run['accuracy_snn'] = accuracy_snn\n",
    "Run['accuracy_buddy'] = accuracy_buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87411c4-4da2-45e4-bd4b-42aaeceeb462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canons</th>\n",
       "      <th>holdout</th>\n",
       "      <th>random_state</th>\n",
       "      <th>dense_layer_length</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>accuracy_sop</th>\n",
       "      <th>accuracy_snn</th>\n",
       "      <th>accuracy_buddy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.948148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   canons  holdout  random_state  dense_layer_length  num_samples  \\\n",
       "0     2.0      0.9           1.0                10.0        250.0   \n",
       "\n",
       "   accuracy_sop  accuracy_snn  accuracy_buddy  \n",
       "0      0.933333      0.933333        0.948148  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([Run])#.to_sql(table, engine, if_exists = if_exists, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c10b46-e14c-4397-bedd-070105ca1a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
