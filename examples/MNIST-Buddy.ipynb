{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e55e65-4ba9-4cc9-aa48-97643b8a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65041f89-ba4e-487a-b601-7e18277256d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    print(Run)\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ae3bc-0a9f-4eb7-8f0d-1edec10041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = 100\n",
    "holdout = 100\n",
    "canons  = 3\n",
    "random_state = 1+21+int(100*holdout)+canons*100\n",
    "num_samples = 5000\n",
    "dense_layer_length = 100\n",
    "table = 'figures'\n",
    "if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f64ab69-d4c7-4493-85f6-0b1a5bd9ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 06:08:19.378315: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 06:08:19.388190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744888099.400045    5080 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744888099.403557    5080 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 06:08:19.415659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Testing images shape: (10000, 28, 28)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verify the shapes of the loaded data\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "\n",
    "# Normalize the pixel values (0-255 to 0-1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5db64-968c-48bf-b281-296d918f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.DataFrame(np.reshape(train_images,(60000,-1))).mean().sort_values(ascending = False)[:100].index\n",
    "\n",
    "X_train = np.reshape(train_images,(60000,-1))[:train,indices]\n",
    "X_test  = np.reshape(test_images,(10000,-1))[:holdout,indices]\n",
    "y_train = train_labels[:train]\n",
    "y_test  = test_labels[:holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3d5e31-85b2-4e71-9390-2967b70084db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(X_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f048365c-7774-45e8-9918-b7c76a7d587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('..')\n",
    "import sopy as sp\n",
    "\n",
    "from connect import conn\n",
    "engine = conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af490b56-5375-4320-910f-bb5f6d49c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = pd.Series()\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,101)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,101))\n",
    "cl= pd.Series(y_train)\n",
    "\n",
    "\n",
    "means    = [ d[c]['mean'] for c in d]\n",
    "sigmas2   =  [ [ 1/1**2 for c in d ] for cl1 in cl.unique() ]\n",
    "\n",
    "\n",
    "spacings  = [ d[c]['std']/4 for c in d]\n",
    "lattices = [ np.arange( d[c]['min'], d[c]['max'], d[c]['std']/4 ) for c in d ]\n",
    "\n",
    "Run['canons'] = canons\n",
    "Run['holdout'] = holdout\n",
    "Run['random_state'] = random_state\n",
    "Run['dense_layer_length'] = dense_layer_length\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,101)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,101))\n",
    "cl= pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8be514-03c5-47fa-bda6-368b23824e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 06:08:23.543582: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "6\n",
      "11\n",
      "11\n",
      "5\n",
      "11\n",
      "10\n",
      "8\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "F = {}\n",
    "for f in range(10):\n",
    "    u = sp.vector()\n",
    "    for index in cl[cl==f].index:\n",
    "        u += sp.vector().gaussian(a=1, ls = 100*[0], positions = ir.loc[index].values, sigmas = sigmas2[f] , lattices = lattices)\n",
    "    F[f] = u.mul(1./u.n())\n",
    "    print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3bd97d0-e55d-410f-922b-efafbb506f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float64, numpy=0.3332932822053197>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5217392717488214>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5488547868589938>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.27878760985549733>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.3923220471124642>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.3864182786047475>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.42795496629189406>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.3934946816436474>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.41045795385508793>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.48204630487024874>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.48211132387486516>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6088832613898839>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6938657410878956>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5432628381230037>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5068483481616997>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5281644675701848>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5523236117576501>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.5682903480772982>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.47954560234490134>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.4900850414968254>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.46972539781655265>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5076913357541772>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5725101240077768>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5633680627806797>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.485916950452826>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.45925357701612185>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.4913086674359513>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.45405286663810235>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5042893962492649>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5054524548168605>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6420591031317117>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.4792584981122597>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6004802950120052>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.44107898495192355>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5724446014381519>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.4788886000531238>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5704978144293992>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.41348906272951014>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5193182178228527>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.44711858096708684>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.50631752423386>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5253437876947481>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.4632199525146447>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7528930583452317>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6608397499197>],\n",
       " []]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ F[i].dot(F[j]) for i in range(j+1,10)] for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a95b66-1e1b-485d-9adf-2d98ccf25333",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_flat_pred = [ [([ v.dot(sp.vector().delta(a=1, positions = x, spacings = spacings , lattices = lattices )) for v in list(F.values()) ])]for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd50ee-82f3-4942-94b1-f8034766bf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54bb1638-6739-47f1-b9fd-fff506e196c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.085052e-49</td>\n",
       "      <td>6.428544e-49</td>\n",
       "      <td>1.913587e-53</td>\n",
       "      <td>2.292324e-52</td>\n",
       "      <td>1.768770e-51</td>\n",
       "      <td>7.219231e-51</td>\n",
       "      <td>2.035557e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.159091e-48</td>\n",
       "      <td>3.635083e-48</td>\n",
       "      <td>8.527773e-53</td>\n",
       "      <td>7.353682e-52</td>\n",
       "      <td>6.937326e-51</td>\n",
       "      <td>2.003712e-50</td>\n",
       "      <td>1.150458e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.440950e-55</td>\n",
       "      <td>1.932758e-55</td>\n",
       "      <td>-1.398463e-54</td>\n",
       "      <td>-1.421970e-56</td>\n",
       "      <td>-8.542317e-59</td>\n",
       "      <td>-1.108187e-59</td>\n",
       "      <td>-2.464726e-61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.924176e-52</td>\n",
       "      <td>5.592956e-52</td>\n",
       "      <td>1.528222e-56</td>\n",
       "      <td>2.209742e-55</td>\n",
       "      <td>1.779809e-54</td>\n",
       "      <td>1.096576e-53</td>\n",
       "      <td>1.595622e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.936433e-51</td>\n",
       "      <td>5.535782e-51</td>\n",
       "      <td>3.945000e-55</td>\n",
       "      <td>4.385870e-54</td>\n",
       "      <td>1.959730e-53</td>\n",
       "      <td>2.105294e-52</td>\n",
       "      <td>1.763709e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.722517e-50</td>\n",
       "      <td>4.508393e-50</td>\n",
       "      <td>2.490886e-54</td>\n",
       "      <td>5.989646e-53</td>\n",
       "      <td>3.616285e-52</td>\n",
       "      <td>2.211553e-51</td>\n",
       "      <td>1.426872e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.861773e-48</td>\n",
       "      <td>3.083477e-47</td>\n",
       "      <td>7.820032e-52</td>\n",
       "      <td>5.753835e-51</td>\n",
       "      <td>5.980874e-50</td>\n",
       "      <td>1.253623e-49</td>\n",
       "      <td>9.761553e-47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count          mean           std           min           25%  \\\n",
       "count  100.0  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean    10.0  2.085052e-49  6.428544e-49  1.913587e-53  2.292324e-52   \n",
       "std      0.0  1.159091e-48  3.635083e-48  8.527773e-53  7.353682e-52   \n",
       "min     10.0 -1.440950e-55  1.932758e-55 -1.398463e-54 -1.421970e-56   \n",
       "25%     10.0  1.924176e-52  5.592956e-52  1.528222e-56  2.209742e-55   \n",
       "50%     10.0  1.936433e-51  5.535782e-51  3.945000e-55  4.385870e-54   \n",
       "75%     10.0  1.722517e-50  4.508393e-50  2.490886e-54  5.989646e-53   \n",
       "max     10.0  9.861773e-48  3.083477e-47  7.820032e-52  5.753835e-51   \n",
       "\n",
       "                50%           75%           max  \n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  \n",
       "mean   1.768770e-51  7.219231e-51  2.035557e-48  \n",
       "std    6.937326e-51  2.003712e-50  1.150458e-47  \n",
       "min   -8.542317e-59 -1.108187e-59 -2.464726e-61  \n",
       "25%    1.779809e-54  1.096576e-53  1.595622e-51  \n",
       "50%    1.959730e-53  2.105294e-52  1.763709e-50  \n",
       "75%    3.616285e-52  2.211553e-51  1.426872e-49  \n",
       "max    5.980874e-50  1.253623e-49  9.761553e-47  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=[np.argmax(y) for y in y_flat_pred]\n",
    "pd.DataFrame(np.transpose([[float(yy) for yy in y[0]] for y in y_flat_pred])).describe().T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a8774c6-1464-4efc-9bb1-32ef1a78a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sop = accuracy_score(y_test, y_pred)\n",
    "accuracy_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd7642a-85d8-4d06-890b-076a0a5063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6200\n"
     ]
    }
   ],
   "source": [
    "##GEMINI GENERATED THIS CODE\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Define the Single Layer Dense Neural Network (Softmax Regression)\n",
    "class SingleLayerNN:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.01, epochs=1000):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5  # Initialize weights randomly\n",
    "        self.bias = np.zeros((1, output_size))  # Initialize bias to zeros\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.weights) + self.bias\n",
    "        self.y_hat = self.softmax(self.z)\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, X, y, y_hat):\n",
    "        m = X.shape[0]\n",
    "        dz = y_hat - self.one_hot_encode(y)\n",
    "        dw = (1/m) * np.dot(X.T, dz)\n",
    "        db = (1/m) * np.sum(dz, axis=0, keepdims=True)\n",
    "        return dw, db\n",
    "\n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(y), self.output_size))\n",
    "        one_hot[np.arange(len(y)), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def update_parameters(self, dw, db):\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.forward(X_train)\n",
    "            dw, db = self.backward(X_train, y_train, y_hat)\n",
    "            self.update_parameters(dw, db)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = self.categorical_cross_entropy(self.one_hot_encode(y_train), y_hat)\n",
    "                #print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_prob = self.forward(X_test)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def categorical_cross_entropy(self, y_true, y_pred):\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        epsilon = 1e-15\n",
    "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "        return loss\n",
    "\n",
    "# 5. Initialize and train the neural network\n",
    "input_size = X_train_scaled.shape[1]  # Number of features (4)\n",
    "output_size = len(np.unique(y_train))  # Number of classes (3)\n",
    "learning_rate = 0.1\n",
    "epochs = 2000\n",
    "\n",
    "model = SingleLayerNN(input_size, output_size, learning_rate, epochs)\n",
    "model.train(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate the model\n",
    "accuracy_snn = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy_snn:.4f}\")\n",
    "\n",
    "# You can also print the classification report for more detailed metrics\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
