{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e55e65-4ba9-4cc9-aa48-97643b8a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65041f89-ba4e-487a-b601-7e18277256d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    print(Run)\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ae3bc-0a9f-4eb7-8f0d-1edec10041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = 100\n",
    "holdout = 100\n",
    "D       = 10\n",
    "canons  = 2\n",
    "random_state = 1+21+int(100*holdout)+canons*100\n",
    "dense_layer_length = 10\n",
    "table = 'figures'\n",
    "if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f64ab69-d4c7-4493-85f6-0b1a5bd9ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 08:17:57.334920: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-21 08:17:57.344914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745241477.356847  226830 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745241477.360355  226830 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-21 08:17:57.372745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Testing images shape: (10000, 28, 28)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verify the shapes of the loaded data\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "\n",
    "# Normalize the pixel values (0-255 to 0-1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5db64-968c-48bf-b281-296d918f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.DataFrame(np.reshape(train_images,(60000,-1))).mean().sort_values(ascending = False)[:D].index\n",
    "\n",
    "X_train = np.reshape(train_images,(60000,-1))[:train,indices]\n",
    "X_test  = np.reshape(test_images,(10000,-1))[:holdout,indices]\n",
    "y_train = train_labels[:train]\n",
    "y_test  = test_labels[:holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3d5e31-85b2-4e71-9390-2967b70084db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(X_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f048365c-7774-45e8-9918-b7c76a7d587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "#chdir('..')\n",
    "import sopy as sp\n",
    "\n",
    "from connect import conn\n",
    "engine = conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af490b56-5375-4320-910f-bb5f6d49c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = pd.Series()\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,D+1)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,D+1))\n",
    "cl= pd.Series(y_train)\n",
    "\n",
    "\n",
    "sigmas   =  [ [ 0.63 for c in d ] for cl1 in cl.unique() ]\n",
    "\n",
    "\n",
    "spacings  = [ d[c]['std']/4 for c in d]\n",
    "lattices = [ np.arange( 0,1, spacings[dd] ) for dd,c in enumerate(d) ]\n",
    "\n",
    "Run['canons'] = canons\n",
    "Run['holdout'] = holdout\n",
    "Run['random_state'] = random_state\n",
    "Run['dense_layer_length'] = dense_layer_length\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,D+1)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,D+1))\n",
    "cl= pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8be514-03c5-47fa-bda6-368b23824e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 08:18:01.403459: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "14\n",
      "6\n",
      "11\n",
      "11\n",
      "5\n",
      "11\n",
      "10\n",
      "8\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "F = {}\n",
    "for f in range(10):\n",
    "    u = sp.vector()\n",
    "    for index in cl[cl==f].index:\n",
    "        u += sp.vector().gaussian(a=1, ls = D*[0], positions = ir.loc[index].values, sigmas = sigmas[f] , lattices = lattices)\n",
    "    F[f] = u.mul(1./u.n()).fibonacci(partition = canons )\n",
    "    \n",
    "    print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bd97d0-e55d-410f-922b-efafbb506f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float64, numpy=0.4668944544163445>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7542447252796998>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6356756819866902>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.27663633098680823>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5469873816523116>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5405492362021794>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5647017929813807>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.49689089291545085>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5062243469552105>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.7055618581774526>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6966995736227118>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7686211024469414>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.813529500029616>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7472225665884072>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7350797292303568>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7858810548331231>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7026401619251208>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.829499141919227>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5080720863338364>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7583590669483009>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8048756616913724>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7695410428802902>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7723124064852563>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8306339759768218>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.5561005963444032>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7622343002180412>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7912928773121396>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7840456890755745>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8482955842435884>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.9128309295183109>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.7765441852174384>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5293376622140251>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8102416995335717>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5419294885418307>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6299297167620855>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6971018018893391>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8312865956076889>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6368838015265299>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7473385770089152>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.7048682221152358>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8869264313606624>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7986469481336766>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6620505599587792>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8366488038003268>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.8227024722774939>],\n",
       " []]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ F[i].dot(F[j]) for i in range(j+1,10)] for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a95b66-1e1b-485d-9adf-2d98ccf25333",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_flat_pred = [ [([ v.dot(sp.vector().delta(a=1, positions = x, spacings = spacings , lattices = lattices )) for v in list(F.values()) ])]for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54bb1638-6739-47f1-b9fd-fff506e196c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.675558330180201e-06)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=[np.argmax(y) for y in y_flat_pred]\n",
    "np.mean( [ max(y) for y in y_flat_pred] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8774c6-1464-4efc-9bb1-32ef1a78a56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sop = accuracy_score(y_test, y_pred)\n",
    "accuracy_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd7642a-85d8-4d06-890b-076a0a5063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.4700\n"
     ]
    }
   ],
   "source": [
    "##GEMINI GENERATED THIS CODE\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Define the Single Layer Dense Neural Network (Softmax Regression)\n",
    "class SingleLayerNN:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.01, epochs=1000):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5  # Initialize weights randomly\n",
    "        self.bias = np.zeros((1, output_size))  # Initialize bias to zeros\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.weights) + self.bias\n",
    "        self.y_hat = self.softmax(self.z)\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, X, y, y_hat):\n",
    "        m = X.shape[0]\n",
    "        dz = y_hat - self.one_hot_encode(y)\n",
    "        dw = (1/m) * np.dot(X.T, dz)\n",
    "        db = (1/m) * np.sum(dz, axis=0, keepdims=True)\n",
    "        return dw, db\n",
    "\n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(y), self.output_size))\n",
    "        one_hot[np.arange(len(y)), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def update_parameters(self, dw, db):\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.forward(X_train)\n",
    "            dw, db = self.backward(X_train, y_train, y_hat)\n",
    "            self.update_parameters(dw, db)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = self.categorical_cross_entropy(self.one_hot_encode(y_train), y_hat)\n",
    "                #print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_prob = self.forward(X_test)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def categorical_cross_entropy(self, y_true, y_pred):\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        epsilon = 1e-15\n",
    "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "        return loss\n",
    "\n",
    "# 5. Initialize and train the neural network\n",
    "input_size = X_train_scaled.shape[1]  # Number of features (4)\n",
    "output_size = len(np.unique(y_train))  # Number of classes (3)\n",
    "learning_rate = 0.1\n",
    "epochs = 2000\n",
    "\n",
    "model = SingleLayerNN(input_size, output_size, learning_rate, epochs)\n",
    "model.train(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate the model\n",
    "accuracy_snn = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy_snn:.4f}\")\n",
    "\n",
    "# You can also print the classification report for more detailed metrics\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5471c0d-8ab2-41cc-9d81-ef6560f69858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3543283-ff38-4d8f-af70-263a23594cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe637a06-e620-48ef-840e-3298cdce4a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e049715-f00f-477e-b52f-4136842bae47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
