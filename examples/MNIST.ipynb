{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e55e65-4ba9-4cc9-aa48-97643b8a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65041f89-ba4e-487a-b601-7e18277256d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canons                   5.0\n",
      "holdout                 10.0\n",
      "random_state          1522.0\n",
      "dense_layer_length      10.0\n",
      "accuracy_sop             0.4\n",
      "accuracy_dnn             0.6\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if flag:\n",
    "    print(Run)\n",
    "flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314ae3bc-0a9f-4eb7-8f0d-1edec10041a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train   = 200\n",
    "holdout = 10\n",
    "D       = 10\n",
    "canons  = 5\n",
    "random_state = 1\n",
    "dense_layer_length = 10\n",
    "table = 'figures'\n",
    "if_exists = 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f64ab69-d4c7-4493-85f6-0b1a5bd9ef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 05:51:23.848814: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 05:51:23.859063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745405483.871191    6139 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745405483.874793    6139 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 05:51:23.887058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Testing images shape: (10000, 28, 28)\n",
      "Testing labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verify the shapes of the loaded data\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "\n",
    "# Normalize the pixel values (0-255 to 0-1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5db64-968c-48bf-b281-296d918f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.DataFrame(np.reshape(train_images,(60000,-1))).mean().sort_values(ascending = False)[:D].index\n",
    "\n",
    "X_train = np.reshape(train_images,(60000,-1))[:train,indices]\n",
    "X_test  = np.reshape(test_images,(10000,-1))[:holdout,indices]\n",
    "y_train = train_labels[:train]\n",
    "y_test  = test_labels[:holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3d5e31-85b2-4e71-9390-2967b70084db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(X_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f048365c-7774-45e8-9918-b7c76a7d587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "#chdir('..')\n",
    "import sopy as sp\n",
    "\n",
    "from connect import conn\n",
    "engine = conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af490b56-5375-4320-910f-bb5f6d49c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run = pd.Series()\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,D+1)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,D+1))\n",
    "cl= pd.Series(y_train)\n",
    "\n",
    "\n",
    "sigmas   =  [ [ 0.63 for c in d ] for cl1 in cl.unique() ]\n",
    "\n",
    "\n",
    "spacings  = [ d[c]['std']/4 for c in d]\n",
    "lattices = [ np.arange( 0,1, spacings[dd] ) for dd,c in enumerate(d) ]\n",
    "\n",
    "Run['canons'] = canons\n",
    "Run['holdout'] = holdout\n",
    "Run['random_state'] = random_state\n",
    "Run['dense_layer_length'] = dense_layer_length\n",
    "\n",
    "d = pd.DataFrame(X_train, columns = range(1,D+1)).describe()\n",
    "ir= pd.DataFrame(X_train, columns = range(1,D+1))\n",
    "cl= pd.Series(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c8be514-03c5-47fa-bda6-368b23824e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 05:51:27.926271: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "26\n",
      "20\n",
      "21\n",
      "21\n",
      "13\n",
      "19\n",
      "21\n",
      "15\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "F = {}\n",
    "for f in range(10):\n",
    "    u = sp.vector()\n",
    "    for index in cl[cl==f].index:\n",
    "        u += sp.vector().gaussian(a=1, ls = D*[0], positions = ir.loc[index].values, sigmas = sigmas[f] , lattices = lattices)\n",
    "    F[f] = u.mul(1./u.n()).fibonacci(partition = canons )\n",
    "    \n",
    "    print(len(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bd97d0-e55d-410f-922b-efafbb506f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float64, numpy=0.5005998468163152>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8219749799250786>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5225195138887204>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.2574739435701595>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6788105774431501>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.48387789329753866>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5329454803066987>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.4352942207439513>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5705535058874565>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.7768075116211924>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7150829500513055>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7071264290644605>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7917690278073853>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7375253939429394>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.679841995207694>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8190373134877299>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7186386550849829>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.8109936076087622>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5310317680201332>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8281061754477813>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7386634546564864>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7148694429114786>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7696330912704797>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8272855557343882>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6017909280380017>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.734307196776193>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8010056588524737>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6981279785662404>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8706688971128632>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.9219385668407585>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6987424938695025>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.5895445491116832>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7842360494499402>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6914571295387973>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.6645196181971736>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.7062665930130213>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8466689745819614>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7084817650159579>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7745943732455699>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6511636964303803>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.8406364363283416>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7674946159341299>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.6674315280397475>,\n",
       "  <tf.Tensor: shape=(), dtype=float64, numpy=0.7869468915238863>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=0.8371199340531446>],\n",
       " []]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ F[i].dot(F[j]) for i in range(j+1,10)] for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a95b66-1e1b-485d-9adf-2d98ccf25333",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_flat_pred = [ [([ v.dot(sp.vector().delta(a= 1/np.sqrt(np.prod(spacings)), positions = x, spacings = spacings , lattices = lattices )) for v in list(F.values()) ])]for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54bb1638-6739-47f1-b9fd-fff506e196c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5742094670446221)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=[np.argmax(y) for y in y_flat_pred]\n",
    "np.mean( [ max(y) for y in y_flat_pred] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8774c6-1464-4efc-9bb1-32ef1a78a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sop = accuracy_score(y_test, y_pred)\n",
    "Run['accuracy_sop'] = accuracy_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd7642a-85d8-4d06-890b-076a0a5063bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "##GEMINI GENERATED THIS CODE\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Define the Single Layer Dense Neural Network (Softmax Regression)\n",
    "class SingleLayerNN:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.01, epochs=1000):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5  # Initialize weights randomly\n",
    "        self.bias = np.zeros((1, output_size))  # Initialize bias to zeros\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Subtract max for numerical stability\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = np.dot(X, self.weights) + self.bias\n",
    "        self.y_hat = self.softmax(self.z)\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, X, y, y_hat):\n",
    "        m = X.shape[0]\n",
    "        dz = y_hat - self.one_hot_encode(y)\n",
    "        dw = (1/m) * np.dot(X.T, dz)\n",
    "        db = (1/m) * np.sum(dz, axis=0, keepdims=True)\n",
    "        return dw, db\n",
    "\n",
    "    def one_hot_encode(self, y):\n",
    "        one_hot = np.zeros((len(y), self.output_size))\n",
    "        one_hot[np.arange(len(y)), y] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def update_parameters(self, dw, db):\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        for epoch in range(self.epochs):\n",
    "            y_hat = self.forward(X_train)\n",
    "            dw, db = self.backward(X_train, y_train, y_hat)\n",
    "            self.update_parameters(dw, db)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = self.categorical_cross_entropy(self.one_hot_encode(y_train), y_hat)\n",
    "                #print(f\"Epoch {epoch + 1}/{self.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_prob = self.forward(X_test)\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def categorical_cross_entropy(self, y_true, y_pred):\n",
    "        # Add a small epsilon to avoid log(0)\n",
    "        epsilon = 1e-15\n",
    "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "        return loss\n",
    "\n",
    "# 5. Initialize and train the neural network\n",
    "input_size = X_train_scaled.shape[1]  # Number of features (4)\n",
    "output_size = len(np.unique(y_train))  # Number of classes (3)\n",
    "learning_rate = 0.1\n",
    "epochs = 2000\n",
    "\n",
    "model = SingleLayerNN(input_size, output_size, learning_rate, epochs)\n",
    "model.train(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 7. Evaluate the model\n",
    "accuracy_snn = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Accuracy: {accuracy_snn:.4f}\")\n",
    "\n",
    "# You can also print the classification report for more detailed metrics\n",
    "#from sklearn.metrics import classification_report\n",
    "#print(\"\\nClassification Report:\")\n",
    "#print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfdc8e3-1835-4a74-a75f-cd4e90e37df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canons                   5.0\n",
       "holdout                 10.0\n",
       "random_state          1522.0\n",
       "dense_layer_length      10.0\n",
       "accuracy_sop             0.4\n",
       "accuracy_dnn             0.6\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Run['accuracy_dnn'] = accuracy_snn\n",
    "Run#.to_sql(table,engine,if_exists = if_exists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
